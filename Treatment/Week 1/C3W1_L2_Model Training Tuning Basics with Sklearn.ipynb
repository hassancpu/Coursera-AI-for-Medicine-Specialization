{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"C3W1_L2_Model Training Tuning Basics with Sklearn.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"fSVXtkQiZB8O","colab_type":"text"},"source":["## AI for Medicine Course 3 Week 1 lecture notebook - Model Training/Tuning Basics with Sklearn"]},{"cell_type":"markdown","metadata":{"id":"3Mq4swQ8ZB8Q","colab_type":"text"},"source":["Welcome to this exercise! You're going to be exploring the `sklearn` library, including an overview of its underlying data types and methods for tweaking a model's hyperparameters. You'll be using the same data from the previous lecture notebook. Let's get started!"]},{"cell_type":"markdown","metadata":{"id":"-bOVWewXZB8R","colab_type":"text"},"source":["### Packages\n","\n","First import all the packages that you need for this assignment. \n","\n","\n","- `pandas` is what you'll use to manipulate your data\n","- `numpy`  is a library for mathematical and scientific operations\n","- `sklearn` has many efficient tools for machine learning and statistical modeling\n","- `itertools` helps with hyperparameter (grid) searching\n","\n","### Import Packages\n","\n","Run the next cell to import all the necessary packages."]},{"cell_type":"code","metadata":{"id":"g2Z65wBiZMIa","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0W7HYd8KZbK-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598070083039,"user_tz":-270,"elapsed":1242,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}}},"source":["import os\n","\n","os.chdir('drive/My Drive/AI for Health/Treatment/Week 1')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"0J19yYhlZB8T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598070239336,"user_tz":-270,"elapsed":1377,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}}},"source":["# Import packages\n","import pandas as pd\n","import numpy as np\n","import itertools\n","\n","# Set the random seed for consistent output\n","np.random.seed(18)\n","\n","# Read in the data\n","data = pd.read_csv(\"dummy_data.csv\", index_col=0)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5jeAmvZZquv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1598070241798,"user_tz":-270,"elapsed":1474,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"cc833316-0e72-43ab-bf32-6cf37e9bb798"},"source":["data.head()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>obstruct</th>\n","      <th>outcome</th>\n","      <th>TRTMT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>68</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>72</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>66</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>69</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sex  age  obstruct  outcome  TRTMT\n","1    0   57         0        1   True\n","2    1   68         0        0  False\n","3    0   72         0        0   True\n","4    0   66         1        1   True\n","5    1   69         0        1  False"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"Y3kZlrvQaIOe","colab_type":"code","colab":{}},"source":["data.drop('outcome', axis= 0)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ldTmP9MZB8Z","colab_type":"text"},"source":["### Train/Test Split"]},{"cell_type":"code","metadata":{"id":"pJyHWYUHZB8Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1598070218339,"user_tz":-270,"elapsed":1752,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"abed8a1d-c6c6-481d-8187-9f70c57aabbf"},"source":["# Import module to split data\n","from sklearn.model_selection import train_test_split\n","\n","# Get the label\n","y = data.outcome\n","\n","# Get the features\n","X = data.drop('outcome', axis=1) \n","\n","# Get training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n","print(f\"Number of observations for training: {y_train.size}\")\n","print(f\"Number of observations for testing: {y_test.size}\")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Number of observations for training: 37\n","Number of observations for testing: 13\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GTweqIa-ZB8f","colab_type":"text"},"source":["### Model Fit and Prediction"]},{"cell_type":"markdown","metadata":{"id":"LxlzoWv0ZB8g","colab_type":"text"},"source":["Let's fit a logistic regression to the training data. `Sklearn` allows you to provide arguments that override the defaults. \n","\n","The default solver is `lbfgs`.  \n","- Lbfgs stands for ['Limited Memory BFGS'](https://en.wikipedia.org/wiki/Limited-memory_BFGS), and is an efficient and popular method for fitting models.\n","- The solver is set explicitly here for learning purposes; if you do not set the solver parameter explicitly, the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) function will use its default solver, which is lbfgs as well."]},{"cell_type":"code","metadata":{"id":"aSUk93NlZB8h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1598070321146,"user_tz":-270,"elapsed":1713,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"98c21926-53fb-4f7a-cbbe-67d8bb2978d3"},"source":["from sklearn.linear_model import LogisticRegression\n","\n","lr = LogisticRegression(solver='lbfgs')\n","lr.fit(X_train, y_train)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"ql042xNFZB8n","colab_type":"text"},"source":["When it fits the training data, `sklearn` also prints out the model's hyperparameters.  \n","- Here, these are the default hyperparameters for `sklearn's` logistic regression classifier.\n","- Another way to check these parameters is the `get_params()` method of the classifier.\n","\n","You should spend some time checking out the [documentation](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) to get a deeper understanding of what's going on. One important thing to note is that each classifier has different hyperparameters. "]},{"cell_type":"markdown","metadata":{"id":"AmqDFQzRZB8n","colab_type":"text"},"source":["### Prediction\n","To predict with the classifier, use the `predict()` method. \n","- This returns a `numpy` array containing the predicted class for each observation in the test set, as you can see by running the next cell:"]},{"cell_type":"code","metadata":{"id":"lZQ8BtMMZB8o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1598070364963,"user_tz":-270,"elapsed":1858,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"c48b4348-007d-49d0-ca9f-f7d62be01119"},"source":["# Use the trained model to predict labels from the features of the test set\n","predictions = lr.predict(X_test)\n","\n","# View the prediction type, shape, and print out a sample prediction\n","print(f\"predictions is of type: {type(predictions)}\")\n","print(f\"predictions has shape: {predictions.shape}\")\n","print(f\"predicted class for 10th element in test set: {predictions[9]}\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["predictions is of type: <class 'numpy.ndarray'>\n","predictions has shape: (13,)\n","predicted class for 10th element in test set: 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4W9p9-KXZB8t","colab_type":"text"},"source":["### Prediction probability\n","\n","When a model predicts that a label is 1 rather than 0, it may help you to know if the model was predicting 1 with a 51% probability or 90% probability; in other words, how confident is that prediction?\n","\n","You can get the model's probability of predicting each of the class. \n","- To do this, use the `predict_proba()` method. \n","- The resulting array will have a shape that matches the number of classes for the target variable."]},{"cell_type":"code","metadata":{"id":"ZI9ezfZKZB8u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1598070400556,"user_tz":-270,"elapsed":2110,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"17e3cdd0-7e9f-4124-d7bf-47af186357d8"},"source":["prediction_probs = lr.predict_proba(X_test)\n","print(f\"prediction_probs is of type: {type(prediction_probs)}\")\n","print(f\"prediction_probs has shape: {prediction_probs.shape}\")\n","print(f\"probabilities for first element in test set: {prediction_probs[0]}\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["prediction_probs is of type: <class 'numpy.ndarray'>\n","prediction_probs has shape: (13, 2)\n","probabilities for first element in test set: [0.42348297 0.57651703]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LOitIPSyZB8z","colab_type":"text"},"source":["There are 13 patients in the test set.  Each patient's label could be either 0 or 1, so the prediction probability has 13 rows and 2 columns.  To know which column refers to lable 0 and which refers to label 1, you can check the `.classes_` attribute."]},{"cell_type":"code","metadata":{"id":"lKmNE5syZB80","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598070425116,"user_tz":-270,"elapsed":1256,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"6305aeb1-e6b6-4a2b-c0c6-0783806c0f5b"},"source":["lr.classes_"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"BIka2ZZwZB86","colab_type":"text"},"source":["Since the order of the `classes_` array is 0, then 1, column 0 of the prediction probabilities has label 0, and column 1 has label 1."]},{"cell_type":"markdown","metadata":{"id":"ov5IE-LwZB86","colab_type":"text"},"source":["Let's print these for the first 5 elements of the dataset:"]},{"cell_type":"code","metadata":{"id":"vZXtMWdMZB87","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"status":"ok","timestamp":1598070442111,"user_tz":-270,"elapsed":2042,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"2c7e0792-568b-4072-b208-a78d37c1ffe0"},"source":["for i in range(5):\n","    print(f\"Element number: {i}\")\n","    print(f\"Predicted class: {predictions[i]}\")\n","    print(f\"Probability of predicting class 0: {prediction_probs[i][0]}\")\n","    print(f\"Probability of predicting class 1: {prediction_probs[i][1]}\\n\")"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Element number: 0\n","Predicted class: 1\n","Probability of predicting class 0: 0.42348296737845204\n","Probability of predicting class 1: 0.576517032621548\n","\n","Element number: 1\n","Predicted class: 1\n","Probability of predicting class 0: 0.4914968703166631\n","Probability of predicting class 1: 0.5085031296833369\n","\n","Element number: 2\n","Predicted class: 1\n","Probability of predicting class 0: 0.483088763245346\n","Probability of predicting class 1: 0.516911236754654\n","\n","Element number: 3\n","Predicted class: 0\n","Probability of predicting class 0: 0.86953653498578\n","Probability of predicting class 1: 0.13046346501422001\n","\n","Element number: 4\n","Predicted class: 0\n","Probability of predicting class 0: 0.8470774295731573\n","Probability of predicting class 1: 0.15292257042684265\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dq1njZyLZB8_","colab_type":"text"},"source":["You can see here that the predicted class matches the class with a higher probability of being predicted. Since you're dealing with `numpy` arrays, you can simply slice them and get specific information, such as the probability of predicting class 1 for all elements in the test set:"]},{"cell_type":"code","metadata":{"id":"L3nhwteEZB9A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1598070475724,"user_tz":-270,"elapsed":1229,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"4f56016a-4ae2-4409-c263-23875c48d249"},"source":["# Retrieve prediction probabilities for label 1, for all patients\n","prediction_probs[:, 1]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.57651703, 0.50850313, 0.51691124, 0.13046347, 0.15292257,\n","       0.26162479, 0.50831618, 0.3190805 , 0.37250246, 0.47736442,\n","       0.15743244, 0.51193665, 0.26832495])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"kOJAhnXkZB9D","colab_type":"text"},"source":["### Tuning the Model"]},{"cell_type":"markdown","metadata":{"id":"V9WfrcvPZB9E","colab_type":"text"},"source":["Most of the time, the predictive power of a classifier can be increased if a good set of hyperparameters is defined. This is known as model tuning. \n","\n","For this process, you'll need a classifier, an appropriate evaluation metric, and a set of parameters to test. Since this is a dummy example, you'll use the default metric for the logistic regression classifier: the **mean accuracy**.\n","\n","### Mean Accuracy\n","Mean Accuracy is the number of correct predictions divided by total predictions. This can be computed with the `score()` method. \n","\n","Let's begin by checking the performance of your out-of-the-box logit classifier:"]},{"cell_type":"code","metadata":{"id":"vhiS00O1ZB9F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598070615019,"user_tz":-270,"elapsed":1540,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"bbc715a4-7dad-4710-c848-ebb05f1dd7c2"},"source":["lr.score(X_test, y_test)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6153846153846154"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"wdY8hAiSZB9K","colab_type":"text"},"source":["Let's say you want to tweak this model's default parameters. You can pass a dictionary containing the values you specify to the classifier when you instantiate it. Notice that these must be passed as keyword arguments, or `kwargs`, which are created by using the ** prefix:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"y8bMg69VZB9L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"status":"ok","timestamp":1598070639126,"user_tz":-270,"elapsed":1431,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"904d9bfa-ff9c-43a4-907f-747b7a0388bb"},"source":["# Choose hyperparameters and place them as key-value pairs in a dictionary\n","params = {\n","    'solver': 'liblinear',\n","    'fit_intercept': False,\n","    'penalty': 'l1',\n","    'max_iter': 500\n","}\n","\n","# Pass in the dictionary as keyword arguments to the model\n","lr_tweaked = LogisticRegression(**params)\n","\n","# Train the model\n","lr_tweaked.fit(X_train, y_train)\n","\n","# View hyper-parameters\n","print(f\"Tweaked hyperparameters: {lr_tweaked.get_params()}\\n\")\n","\n","# Evaluate the model with the mean accuracy\n","print(f\"Mean Accuracy: {lr_tweaked.score(X_test, y_test)}\")"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Tweaked hyperparameters: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': False, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 500, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n","\n","Mean Accuracy: 0.5384615384615384\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0rXQrkl8ZB9P","colab_type":"text"},"source":["The model with the tweaked parameters is worse than the original! However, there might still be some combination of parameters that increase the predictive power of your logit classifier. "]},{"cell_type":"markdown","metadata":{"id":"HSjUKf-lZB9P","colab_type":"text"},"source":["### Try different hyperparameters\n","Testing this can be daunting considering all the possible parameter combinations. Let's try something \n","\n","To get started, you'll apply `itertools.product()` to create all the combinations of parameters. \n","- Notice that the iterable (in this case a list of the lists of parameters) must be passed as *args to the `product()` function."]},{"cell_type":"code","metadata":{"id":"EN3xfkAHZB9Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598070700291,"user_tz":-270,"elapsed":1879,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"77734053-54f0-4416-8184-998d370b5a82"},"source":["# Choose hyperparameters and place in a dictionary\n","hyperparams = {\n","    'solver': [\"liblinear\"],\n","    'fit_intercept': [True, False],\n","    'penalty': [\"l1\", \"l2\"],\n","    'class_weight': [None, \"balanced\"]\n","}\n","# Get the values of hyperparams and convert them to a list of lists\n","hp_values = list(hyperparams.values())\n","hp_values"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['liblinear'], [True, False], ['l1', 'l2'], [None, 'balanced']]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"xNuVpDw9ZB9U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"status":"ok","timestamp":1598070711398,"user_tz":-270,"elapsed":2795,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"2d391d67-6cc1-4cef-cd29-1a53de498818"},"source":["# Get every combination of the hyperparameters\n","for hp in itertools.product(*hp_values):\n","    print(hp)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["('liblinear', True, 'l1', None)\n","('liblinear', True, 'l1', 'balanced')\n","('liblinear', True, 'l2', None)\n","('liblinear', True, 'l2', 'balanced')\n","('liblinear', False, 'l1', None)\n","('liblinear', False, 'l1', 'balanced')\n","('liblinear', False, 'l2', None)\n","('liblinear', False, 'l2', 'balanced')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gwW-ljwnZB9Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"status":"ok","timestamp":1598070732330,"user_tz":-270,"elapsed":1398,"user":{"displayName":"Hassan KeshvariKhojasteh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRHRYK7qaghAdYe4qnimiyyI9MZjzoeZ_MpF_o=s64","userId":"00516321613958861415"}},"outputId":"f8986a38-f0fb-4bdb-eff4-2ea5bd48103d"},"source":["# Loop through the combinations of hyperparams\n","for hp in itertools.product(*hp_values):\n","\n","    # Create the model with the hyperparams\n","    estimator = LogisticRegression(solver=hp[0],\n","                                   fit_intercept=hp[1],\n","                                   penalty=hp[2],\n","                                   class_weight=hp[3])\n","    # Fit the model\n","    estimator.fit(X_train, y_train)\n","    print(f\"Parameters used: {hp}\")\n","    print(f\"Mean accuracy of the model: {estimator.score(X_test, y_test)}\\n\")"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Parameters used: ('liblinear', True, 'l1', None)\n","Mean accuracy of the model: 0.5384615384615384\n","\n","Parameters used: ('liblinear', True, 'l1', 'balanced')\n","Mean accuracy of the model: 0.46153846153846156\n","\n","Parameters used: ('liblinear', True, 'l2', None)\n","Mean accuracy of the model: 0.38461538461538464\n","\n","Parameters used: ('liblinear', True, 'l2', 'balanced')\n","Mean accuracy of the model: 0.46153846153846156\n","\n","Parameters used: ('liblinear', False, 'l1', None)\n","Mean accuracy of the model: 0.5384615384615384\n","\n","Parameters used: ('liblinear', False, 'l1', 'balanced')\n","Mean accuracy of the model: 0.46153846153846156\n","\n","Parameters used: ('liblinear', False, 'l2', None)\n","Mean accuracy of the model: 0.3076923076923077\n","\n","Parameters used: ('liblinear', False, 'l2', 'balanced')\n","Mean accuracy of the model: 0.46153846153846156\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Aaxrk1KjZB9c","colab_type":"text"},"source":["Note that in the graded assignment, you will take a more generalizable approach that doesn't require you to explicitly specify each hyperparameter.\n","\n","That is, instead of:\n","\n","```CPP\n","LogisticRegression(solver=hp[0],fit_intercept=hp[1],...\n","```\n","\n","You'll be able to write:\n","```CPP\n","LogisticRegression(**params)\n","```"]},{"cell_type":"markdown","metadata":{"id":"oIJEGr41ZB9d","colab_type":"text"},"source":["Looks like none of these models beats the original! This won't always be the case, so next time the opportunity arises, you'll be able to check this for yourself. "]},{"cell_type":"markdown","metadata":{"id":"B_3Q3gI8ZB9d","colab_type":"text"},"source":["### Grid Search\n","\n","This is essentially grid search.  You'll be implementing customized grid search in the graded assignment.  \n","- Note that even though sci-kit learn provides a grid search function, it uses K-fold cross validation, which you won't want to do in the assignment, which is why you will implement grid search yourself."]},{"cell_type":"markdown","metadata":{"id":"Kb0fm7SbZB9e","colab_type":"text"},"source":["### Congratulations on completing this lecture notebook! \n","\n","By now, you should feel more comfortable with the `sklearn` library and how it works. You also created a grid search from scratch by leveraging the `itertools` library. Nice work!"]}]}